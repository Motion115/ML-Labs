# ML-Lab2: Classification

**CoraR dataset**: "We double-check the articles belong to Cora [Lu and Getoor, 2003] dataset in the original Cora [McCallum et al., 2000]. Among the 2,708 papers, 474 of them have a wrong title that can hardly be found on any academic search engines such as google scholar or aminer [Tang et al., 2008]. We manually searched for these papers based on other information like author, abstract, references and feature vectors in Cora. Finally, we figure out that 32 of the total 2,708 papers are duplicated papers that actually belong to 13 identical ones. 9 papers are absolutely missing and not able to trace. We recover the actual title of the rest 2,680 papers, and use their titles to generate their features. We apply averaged GLOVE-300 [Pennington et al., 2014] word vector for their titles(with stop words removed) and we add two dimensions expressing the length of the title, and the length of the title with stop words removed. This leads to a 302 dimension feature representation for each node in CoraR. The average and word embedding process can better reduce the effect of label information leak than using simple BOW vectors. As in [Hamilton et al., 2017, Chen et al., 2018], we split the 2,680 nodes into a training set of 1,180 nodes, a validation set of 500 nodes and a test set of 1,000 nodes."

https://arxiv.org/pdf/1907.02237.pdf